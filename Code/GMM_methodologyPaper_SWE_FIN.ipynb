{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d2da8f-19a0-4526-b7bb-414557bccdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import requests\n",
    "#import json\n",
    "#import zipfile\n",
    "import datetime\n",
    "import time\n",
    "#from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import shape\n",
    "import utils\n",
    "import importlib\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import nimfa\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63e646a7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\hildlars\\\\OneDrive - Universitetet i Oslo\\\\NordicMathCovid\\\\GitProjects\\\\NordicMobilityData_WorkingRepo\\\\PythonCode\\\\GaussianMixture\\\\utils.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b141e071-f28d-4a29-b506-ae3d68486819",
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderPath = '../Data/FinSwe/' # Path to raw data files for SWE-FIN sensors.\n",
    "\n",
    "Sensors = [\"1433\",\"1432\",\"1435\",\"1436\",\"1431\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a518567",
   "metadata": {},
   "source": [
    "Read data for each sensor, from .csv files downloaded using the function 'get_traffic_FIN()' in the file road_traffic_data_methodologyPaper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e1a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sensor_dict = {}\n",
    "all_data = pd.DataFrame()\n",
    "for s in Sensors:\n",
    "    sensor_data = pd.read_csv(FolderPath+s+'_by_length_minute.csv', sep=',',usecols= ['TMS point id', 'year', 'days', 'hour','minute', 'v_type', 'direction', 'total_vehicles', 'date'], parse_dates=['date'])\n",
    "\n",
    "    all_data = pd.concat([all_data,sensor_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65866b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WhichVehicles = 'Small'\n",
    "data = all_data.copy()\n",
    "min_date = datetime.datetime(2017, 1, 1)\n",
    "max_date = datetime.datetime(2023, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abaebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_APIdata_SWEFIN(data,WhichVehicles,min_date = datetime.datetime(2017, 1, 1)  , max_date = datetime.datetime(2023, 5, 22)):\n",
    "\n",
    "#WhichVehicles can be 'Small', 'Heavy', 'Total' or 'Both' \n",
    "\n",
    "    agg_data = data[['TMS point id','hour','minute', 'v_type', 'direction', 'total_vehicles', 'date']].reset_index(drop = True).copy()\n",
    "    \n",
    "    # What vehicle lengths do we want\n",
    "    if WhichVehicles == 'Total':\n",
    "        agg_data = agg_data.groupby(['TMS point id','hour','minute','direction','date'])['total_vehicles'].sum().reset_index()\n",
    "    elif WhichVehicles == 'Small':\n",
    "        agg_data = agg_data[agg_data['v_type']=='<5.6m'].drop(columns='v_type').reset_index()\n",
    "    elif WhichVehicles == 'Heavy':\n",
    "        agg_data = agg_data[agg_data['v_type']=='>=5.6m'].drop(columns='v_type').reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    agg_data = agg_data.rename({'TMS point id': 'sensor_id',\n",
    "                                'direction': 'sensor_dir'},axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    agg_data['dest_country'] = np.where(agg_data['sensor_dir'] == 2, 'FIN','SWE')\n",
    "    agg_data['origin_country'] = np.where(agg_data['sensor_dir'] == 2, 'SWE','FIN')\n",
    "\n",
    "    ##Create a new variables that contain both sensor name and country name\n",
    "    agg_data[\"sensor_id\"] = agg_data[\"sensor_id\"].astype(str)\n",
    "    agg_data['sensor_origin'] = agg_data[['sensor_id', 'origin_country']].agg(', '.join, axis=1)\n",
    "    agg_data['sensor_destination'] = agg_data[['sensor_id', 'dest_country']].agg(', '.join, axis=1)\n",
    "\n",
    "\n",
    "    agg_data[\"minute\"] = pd.to_timedelta(agg_data[\"minute\"], unit=\"min\")\n",
    "    agg_data[\"hour\"] = pd.to_timedelta(agg_data[\"hour\"], unit=\"h\")\n",
    "\n",
    "\n",
    "    agg_data['date'] = agg_data['date'] + agg_data['hour'] + agg_data['minute']\n",
    "    agg_data = agg_data[(agg_data.date > min_date) & (agg_data.date < max_date)].copy().reset_index()\n",
    "    \n",
    "\n",
    "    min_date = agg_data.date.min()\n",
    "    max_date = agg_data.date.max()\n",
    "\n",
    "    if WhichVehicles == 'Both':\n",
    "        agg_data = agg_data[['sensor_origin','sensor_destination','date','v_type','total_vehicles']].copy()\n",
    "\n",
    "    else:\n",
    "        agg_data = agg_data.groupby(['sensor_origin', 'sensor_destination', 'date'])['total_vehicles'].sum().reset_index().copy()\n",
    "        rm_idx = np.where(np.isnan(agg_data.total_vehicles))\n",
    "        agg_data = agg_data.drop(index = rm_idx[0])\n",
    "        agg_data['total_vehicles'] = agg_data['total_vehicles'].apply(lambda x: int(x))\n",
    "\n",
    "        f = lambda x: x.reindex(pd.date_range(min_date,\n",
    "                                                max_date,\n",
    "                                                name='date',\n",
    "                                                freq='1min'), fill_value=0)\n",
    "\n",
    "    #return(data)\n",
    "\n",
    "        agg_data = (agg_data.set_index('date')\n",
    "                    .groupby([\"sensor_origin\", \"sensor_destination\"])[\"total_vehicles\"]\n",
    "                    .apply(f)\n",
    "                    .reset_index())\n",
    "        agg_data = agg_data.pivot_table(index=[\"sensor_origin\",\"sensor_destination\"], columns=[\"date\"],values=[\"total_vehicles\"] ).droplevel(level = 0,axis = 1 )\n",
    "\n",
    "    return(agg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55c2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2017-2023 this takes about 4 min to run\n",
    "agg_data = agg_APIdata_SWEFIN(all_data, 'Small',min_date = datetime.datetime(2017, 1, 1)  , max_date = datetime.datetime(2023, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f03e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hildlars\\OneDrive - Universitetet i Oslo\\NordicMathCovid\\PanNordicMobility\\FinalFiles_commutingPaper\\Code\\utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n"
     ]
    }
   ],
   "source": [
    "# This takes about 18 min to run\n",
    "models_pre, data_pre = utils.fit_period(agg_data, d1=datetime.date(2017,1,1), d2=datetime.date(2020,3,1), hourly = False, nSamp = 10000, Normalize = False, N = 10, seed=1923, FitMethod = 'Bayesian')\n",
    "# Save the fitted model and data\n",
    "models_pre.to_pickle('../Data/models_fin.pkl')\n",
    "data_pre.to_pickle('../Data/data_fin.pkl')\n",
    "agg_data.to_pickle('../Data/agg_data_fin.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27f721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "142fce53b6f2b91b97dca80dfeb7f3677964d22b620fffd446cffe90630072c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
